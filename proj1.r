# Member1：Chunxi Su（UNN：s2814164）；Member2：Huaidong Yue（UNN：s2815318）；Member3：Yifei Peng（UNN：s2792136）

# Project Intruduction:
#   This project creates a simple “small language model” based on all of Shakespeare's works. 
#   It produces coherent sentences in the style of Shakespeare using a Markov chain model and compares 
#   them with sentences generated by randomly choosing words to test the model's ability to capture 
#.  textual patterns.

## Contribution Instruction：
# Member1: Chunxi Su (UNN: s2814164) - 33%
#   - Implemented text preprocessing:
#     1. split_punct(): Separates punctuation from words (supports all required marks);
#     2. clean_text(): Removes stage directions ([]), all-uppercase names/headings, numbers, spaces, and converts to lowercase;
#   - Verified text reading and preprocessing output.
# 
# Member2: Huaidong Yue (UNN: s2815318) - 34%
#   - Implemented word frequency and sequence matrix:
#     1. vocabulary_constr_and_freq(): Builds vocabulary and counts word frequencies;
#     2. matrix_construction(): Filters top 1000 frequent words, generates token vector, and builds Markov matrix M;
#.    3. random_sentence(): Generate a random sentence by randomly selecting words from the common vocabulary and compare to Markov chain result.
#   - Tuned hyperparameter 'mlag' and validated matrix dimensions.
#.  - Review code and support function test
# 
# Member3: Yifei Peng (UNN: s2792136) - 33%
#   - Implemented core prediction and sentence generation:
#     1. next.word(): Predicts next token via multi-order matching and weighted sampling;
#     2. simulate_sentence(): Generates coherent sentences (stops at "." or max length 50);
#   - Added comparison with random word sequences and test examples.
##

#setwd("/Users/clggmac/Rprogramming/Shakespeare-project/shakespeare-text-project18")  ## The setwd line should be commented out of the code you finally submit for marking！！！
# setwd("D:/scx Work/programming/R/Rprogramming/shakespeare-text-project18")  ## The setwd line should be commented out of the code you finally submit for marking！！！
# reading text：skip first 83 rows（invalid instruction）,reading 196043-83 row（valid text）,coding with UTF-8
a <- scan("shakespeare.txt",
          what = "character", 
          skip = 83,
          nlines = 196043 - 83,
          fileEncoding = "UTF-8")

## Member1: Text Preprocessing Module

##
# function:split_punct()
# purpose:
#   This function handles the situation where words and punctuation are not separated when reading text
#   It separates punctuation marks from words, such as the element "word," will becomes two elements: "word" and ",".
#   1.Remove the punctuation mark from the word
#   2.Insert the punctuation mark as a new element after the word
# 
# input:
#   a -a vector of character, in which some elements contain both word and punctuation mark
#   punct -a vector of punctuation marks to be split off(default includes ",", ".", ";", ":", "!", "?", "(", ")", "\"", "'")
# 
# output: 
#   sp_a -a character vector which punctuation has been separated into individual elements
#         unrecognized punctuation marks will be retained
##
split_punct <- function(a, punct=c(",", "\\.", ";", ":", "!", "\\?", "\\(", "\\)", "\"", "'")){
  
  sp_a <- vector("list", length(a))
  
  punct_pat <- paste(punct, collapse="|")
  
  #Process each element in a separately.
  for(i in 1:length(a)){
    w <- a[i]
    
    if(length(grep(punct_pat, w)) == 0){
      sp_a[[i]] <- w # If no punctuation mark, keep it
    }
    else{
      
      w_2 <- w
      
      #Split words with punctuation.
      for(p in punct){
        if(length(grep(p, w_2)) > 0){
          w_2 <- gsub(p, "", w_2)
          sp_a[[i]] <- c(w_2, gsub("\\\\", "", p))
          w_2 <- ""
          break
        }
      }
      
      if(w_2 != ""){
        sp_a[[i]] <- w_2 # Prevent unrecognized punctuation marks
      }
    }
  }
  
  return(unlist(sp_a))
  
}

##
# function:clean_text()
# purpose:
#   This function aims to clean the Shakespeare text vector 'a' by removing irrelevant elements and standardizing the text. 
#   Specifically, it includes:
#   Removes stage directions (enclosed in square brackets, e.g. [Aaa Bbb])
#   Removes Words that are fully upper case except "I" and "A" (character names or headings of various sorts)
#   Remove numeric labels(They are not part of the text in the works of Shakespeare)
#   Remove “_” and "-"
#   Use split_punct function to separate the punctuation marks
#   Convert to lowercase(For simplicity and to unify the forms of all words)
# input:a-a vector of character
# 
# output:a- the cleaned vector a
##
clean_text <- function(a){
  
  # Remove stage directions (in [])
  a_bracket_le <- grep("\\[", a)
  a_bracket_ri_all <- grep("\\]", a)
  
  a_remove <- rep(TRUE, length(a)) # Mark parts to keep (TRUE = keep, FALSE = remove)
  
  for(i in a_bracket_le){
    # Find the first "]" after "[" (within 100 steps to avoid over-removal)
    a_bracket_ri <- a_bracket_ri_all[a_bracket_ri_all > i & a_bracket_ri_all <= i + 100]
    
    if(length(a_bracket_ri) == 0){
      j <- i # Single "[" case: only remove the "["
    }
    else{
      j <- a_bracket_ri[1]
    }
    
    a_remove[i:j] <- FALSE # Mark content in [] as to remove
  }
  
  a <- a[a_remove]
  
  # Remove character names/headings/numbers
  # Rule: Remove words that are all uppercase (except "I" and "A") + pure numbers
  a_remove <- a == toupper(a)
  a_remove[grep("^[0-9]+$", a)] <- TRUE
  a_remove[grep("^(I|A)$", a)] <- FALSE
  a <- a[!a_remove]
  
  # Remove “_” and "-" (split words if needed, then clean)
  a <- unlist(strsplit(a, "_"))
  a <- gsub("_", "", a)
  a <- unlist(strsplit(a, "-"))
  a <- gsub("-", "", a)
  
  # Separate punctuation marks
  a <- split_punct(a)
  
  # Convert to lowercase
  a <- tolower(a)
  
  return(a)
}

## Member2: Word Frequency & Sequence Matrix Module

##
# function:vocabulary_constr_and_freq()
# author:Huaidong Yue
# date:25/09/2025
# purpose:
#   1.Vocabulary Construction
#   2.Word Frequency Statistics
# 
# input:
#   pre_words: vector of split, cleaned character
# 
# output: 
#   word_counts: counts of each unique word
##
vocabulary_constr_and_freq <- function(pre_words){
  pre_words<-tolower(pre_words)
  
  #Retrieve all unique words in the cleaned text
  unique_words<-unique(pre_words)
  
  # Map words to their indices in the unique vocabulary
  word_indices<-match(pre_words, unique_words)
  
  # Count occurrences of each unique word
  word_counts<-tabulate(word_indices)
  names(word_counts)<-unique_words
  
  return(word_counts)
}

##
# function:matrix_construction()
# author:Huaidong Yue
# date:25/09/2025
# purpose:
#   Common word marker sequence matrix construction
# 
# input:
#   word_counts: counts of each unique word.
#   mlag: lag order.
#   a: character vector. Cleaned text data, where elements are words or punctuation marks in lowercase. 
# 
# output: 
#   A list containing three elements:
#   - M: matrix. Sequence matrix with dimensions (n - mlag) × (mlag + 1), where n is the length of token_vec.
#        Each row represents a sliding window of token indices; columns correspond to lagged positions.
#   - b: character vector. Top 1000 most frequent words from the cleaned text.
#   - token_vec: Integer vector. Mapping of each element in 'a' to its index in 'b' (NA if not in 'b').
##
matrix_construction <- function(word_counts, mlag, a){
  #Filter top 1000 most common words
  k<-1000
  sorted_words<-names(sort(word_counts, decreasing = TRUE))
  b<-sorted_words[1:min(k, length(sorted_words))]
  
  #Generate token vector: map cleaned words to indices of common words (NA if not in common_words)
  token_vec<-match(a, b)

  n<-length(token_vec)
  if (n<=mlag) {
    stop("The text length is insufficient to construct matrix M.")
  }
  
  #Initialize sequence matrix M
  M<-matrix(NA,nrow = n - mlag,ncol = mlag + 1)
  
  for(col in 1:(mlag+1)) {
    M[, col] <- token_vec[col : (col + n - mlag - 1)]
  }
  
  return(list(M = M, b=b, token_vec = token_vec))
}

## Member3: Core function development and sentence generation module

##
# Function: next.word()
# Author: Yifei Peng
# Date: 25/09/2025
# Purpose:
#   Predict the token of the next word based on the Markov sequence matrix (M) and the current word sequence (key).
# 
# Inputs:
#   key: Integer vector. The token sequence of the current word(s) 
#   M: Matrix. The sequence matrix generated by the matrix_construction() function (rows = sliding windows, columns = lagged tokens).
#   M1: Integer vector. The global token vector (token_vec) representing the token sequence of the entire text. 
#       Defaults to the global variable 'token_vec' if not specified.
#   w: Numeric vector. Weight vector for multi-order matching (equal weights by default). Length must match 'mlag'.
# 
# Output:
#   Integer. The token of the next word (corresponds to the index of the common word list 'b').
##
next.word <- function(key, M, M1 = token_vec, w=rep(1, ncol(M)-1)) {
  #If the length of 'key' exceeds 'mlag', keep only the last 'mlag' tokens
  if (length(key) > mlag){
    key <- tail(key, mlag)
  } 
  
  candidates <- c() 
  probs <- c()
  
  key_len <- length(key)
  #Start matching from the longest subkey and gradually reduce the order
  for (i in seq_len(key_len)) {
    subkey <- tail(key, i)
    mc <- mlag - i + 1
    
    ii <- colSums(!(t(M[, mc:mlag, drop=FALSE]) == subkey))
    match_rows <- which(ii == 0 & is.finite(ii))
    
    if (length(match_rows) > 0) {
      u <- M[match_rows, mlag+1]
      u <- u[!is.na(u)]  
      if (length(u) > 0) {
        probs <- c(probs, rep(w[i] / length(u), length(u)))
        candidates <- c(candidates, u)
      }
    }
  }
  
  #Fallback: If no candidates are found, randomly sample a valid token from the full text
  if (length(candidates) == 0) {
    return(sample(M1[!is.na(M1)], 1))
  }
  
  #Merge probabilities for duplicate tokens
  prob_table <- tapply(probs, candidates, sum)
  
  #Remove NA entries
  prob_table <- prob_table[!is.na(prob_table)]
  if (length(prob_table) == 0) {
    valid_tokens <- M1[!is.na(M1)]
    return(sample(valid_tokens, 1))
  }
  
  #Normalize probabilities to ensure they sum to 1
  prob_table <- prob_table / sum(prob_table)
  
  #Weighted sampling to select the next token
  next_token <- sample(names(prob_table), 1, prob = prob_table)
  return(as.numeric(next_token))
  
}

##
# Function: simulate_sentence()
# Author: Yifei Peng
# Date: 25/09/2025
# Purpose:
#   Generate a coherent sentence using the Markov chain model
# 
# Inputs:
#   M: markov matrix constructed from text data
#   M1: full token sequence of the original text 
#   b: common word vocabulary
#   start_word: optional starting word (string); if NULL, a random valid token is selected
#   mlag: lag order for sequence prediction
# 
# Output: 
#   Generated sentence as a formatted string
##
simulate_sentence <- function(M, M1=token_vec, b, start_word=NULL, mlag=ncol(M) - 1) {
  #Select starting token
  if (is.null(start_word)) {
    valid_tokens <- M1[!is.na(M1)]
    if (length(valid_tokens) == 0) {
      stop("No valid tokens available for starting the sentence")
    }
    start_token <- sample(valid_tokens, 1)
  } else {
    start_token <- match(start_word, b)
    if (is.na(start_token)) {
      stop("Starting word not found in the common vocabulary")
    }
  }

  sentence_tokens <- c(start_token)
  
  #Continuously predict next tokens until termination condition
  repeat {
    #Extract current context (up to mlag most recent tokens)
    key <- tail(sentence_tokens, mlag)
    
    next_token <- next.word(key, M, M1)
    sentence_tokens <- c(sentence_tokens, next_token)
    
    #Terminate if period is generated
    if (b[next_token] == ".")  {
      break
    }
    if (length(sentence_tokens) > 50) {
      break
    }
  }
  
  words <- b[sentence_tokens]
  
  sentence <- paste(words, collapse=" ")
  sentence <- gsub(" ([,.;:!?])", "\\1", sentence)
  sentence <- trimws(sentence)
  return(sentence)
}

##
# Function: random_sentence()
# Author: Huaidong Yue
# Date: 25/09/2025
# Purpose:
#   Generate a random sentence by randomly selecting words from the common vocabulary until a period is encountered or the maximum length is reached
# 
# Inputs:
#   b: character vector. Common word vocabulary 
#   max_len: integer. Maximum length of the generated sentence
# 
# Output: 
#   A formatted random sentence as a string, with proper punctuation spacing
##
random_sentence<-function(b, max_len = 50) {
  #Filter valid words from common word list B
  valid_words <- b[!is.na(b)]
  if (!"." %in% valid_words) {
    stop("The common word list lacks a period, preventing the termination of random sentences.")
  }
  
  random_words <- c()
  
  #Randomly select words in a loop until a period is generated or the maximum length is reached.
  while (TRUE) {
    next_word <- sample(valid_words, 1)
    random_words <- c(random_words, next_word)
    
    if (next_word == "." || length(random_words) >= max_len) {
      break
    }
  }

  random_sent <- paste(random_words, collapse = " ")
  random_sent <- gsub(" ([,.;:!?])", "\\1", random_sent)
  random_sent <- trimws(random_sent)
  
  return(random_sent)
}

# data clean
a <- clean_text(a)

# word frequency statistics and matrix construction
word_counts <- vocabulary_constr_and_freq(a)
mlag <- 4
result <- matrix_construction(word_counts, mlag, a)
M <- result$M
b <- result$b
token_vec <- result$token_vec

# sentence generation and comparison
model_sent <- simulate_sentence(M, token_vec, b, start_word = 'the')
random_sent <- random_sentence(b)

final_output <- paste(
  "=== Shakespeare Text Sentence Generation Output ===\n",
  "1. Markov model generation：\n  ", model_sent, "\n\n",
  "2. Randomly generate words：\n  ", random_sent, "\n",
  sep = ""
)
cat(final_output)
